GitHub Copilot Prompts for Taglish Sentiment Project

Use these prompts to generate your project step-by-step.

Step 1: Setup Dependencies

Target File: requirements.txt
Copilot Prompt:

"Create a requirements.txt file for a machine learning project using TensorFlow, Pandas, NumPy, Scikit-learn, and Matplotlib."

Step 2: The Data Processor (Taglish Logic)

Target File: data_processor.py
Context: We need to handle Tagalog-English code-switching. Standard English cleaners remove words like "ang", "ng", "hindi" which are critical in Tagalog.
Copilot Prompt:

"Write a Python class named TaglishProcessor using TensorFlow Tokenizer and Pad Sequences.

Include a clean_text method that converts text to lowercase and removes HTML tags, but KEEPS punctuation and stopwords (do not remove Tagalog stopwords).

Include a load_and_prep_data method that takes a filepath, loads a CSV, cleans the 'review_text' column, and tokenizes it.

It should split the data into Training, Validation, and Test sets (70/15/15 split).

Return the padded sequences and labels."

Step 3: The Model Architecture (LSTM)

Target File: model_builder.py
Context: The rubric requires "training from scratch" (no pre-trained BERT). We need an LSTM.
Copilot Prompt:

"Create a function build_lstm_model using TensorFlow Keras Sequential API.
The function should accept arguments: vocab_size, embedding_dim, max_length, lstm_units, and dropout_rate.
The architecture must have:

An Embedding layer (trained from scratch).

A Bidirectional LSTM layer.

A Dropout layer for regularization.

A Dense output layer with sigmoid activation for binary classification."

Step 4: The Training Script & Logging

Target File: train_runner.py
Context: The rubric requires you to log hyperparameter tuning. We need Copilot to write code that saves these stats automatically.
Copilot Prompt:

"Write a main training script that uses TaglishProcessor and build_lstm_model.

Define constants at the top for hyperparameters: VOCAB_SIZE=5000, MAX_LENGTH=100, EMBEDDING_DIM=64, LSTM_UNITS=64, DROPOUT=0.5, LEARNING_RATE=0.001.

Load the data using the processor.

Compile the model using Adam optimizer with the defined learning rate.

Train the model for 5 epochs using the validation set.

Evaluate the model on the test set.

Crucial: Append the hyperparameters and the final Test Accuracy to a CSV file named 'hyperparameter_logs.csv' so I can track my experiments."

Step 5: The Predictor (Demo)

Target File: predict.py
Context: You need a script to show your professor during the demo.
Copilot Prompt:

"Write a script to load the saved Keras model and the tokenizer.
Create a function predict_sentiment that accepts a text string, preprocesses it using the same logic as training, and prints whether the sentiment is 'Positive' or 'Negative' based on a 0.5 threshold.
Add a while-loop at the end to let me type reviews interactively in the terminal."

Tips for Copilot Interaction

If Copilot imports a library you don't have: Open your terminal and type pip install [library_name].

If the code looks wrong: Highlight the specific code block, right-click, select "Copilot > Fix This", and type "It is ignoring Tagalog words" or whatever the issue is.

For the 'From Scratch' requirement: If Copilot tries to import hub or bert, tell it: "Do not use pre-trained models. Use a standard Keras Embedding layer."